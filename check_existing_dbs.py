#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê¸°ì¡´ DB êµ¬ì¡° í™•ì¸ ìŠ¤í¬ë¦½íŠ¸
ì‘ì„±ì¼: 2025ë…„ 1ì›” 13ì¼
ì‘ì„±ì: ì„œëŒ€ë¦¬ (Lead Developer)
ëª©ì : ì¡°ëŒ€í‘œë‹˜ì˜ ê¸°ì¡´ í”„ë¡œì íŠ¸, íƒœìŠ¤í¬, TODO DB êµ¬ì¡° íŒŒì•…
"""

import json
import logging
from typing import Dict, List
from notion_client import Client
from mvp_config import APIConfig

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/existing_db_check.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class ExistingDBChecker:
    """ê¸°ì¡´ DB êµ¬ì¡° í™•ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.notion = Client(auth=APIConfig.NOTION_API_TOKEN)
        self.dbs = {
            "í”„ë¡œì íŠ¸": APIConfig.NOTION_PROJECT_DATABASE_ID,
            "íƒœìŠ¤í¬": APIConfig.NOTION_TASK_DATABASE_ID,
            "TODO": APIConfig.NOTION_TODO_DATABASE_ID
        }
    
    def check_database_structure(self, db_name: str, db_id: str) -> Dict:
        """DB êµ¬ì¡° í™•ì¸"""
        try:
            logging.info(f"ğŸ“Š {db_name} DB êµ¬ì¡° í™•ì¸ ì¤‘... ({db_id})")
            
            # DB ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            db_info = self.notion.databases.retrieve(database_id=db_id)
            
            # ì†ì„± ì •ë³´ ì¶”ì¶œ
            properties = db_info.get('properties', {})
            
            structure = {
                "db_name": db_name,
                "db_id": db_id,
                "title": db_info.get('title', [{}])[0].get('plain_text', ''),
                "properties": {},
                "property_count": len(properties)
            }
            
            # ê° ì†ì„±ì˜ ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ
            for prop_name, prop_info in properties.items():
                prop_type = prop_info.get('type', 'unknown')
                
                structure["properties"][prop_name] = {
                    "type": prop_type,
                    "id": prop_info.get('id', '')
                }
                
                # ì„ íƒ íƒ€ì…ì˜ ê²½ìš° ì˜µì…˜ ì •ë³´ ì¶”ê°€
                if prop_type == 'select':
                    options = prop_info.get('select', {}).get('options', [])
                    structure["properties"][prop_name]["options"] = [
                        option.get('name', '') for option in options
                    ]
                elif prop_type == 'multi_select':
                    options = prop_info.get('multi_select', {}).get('options', [])
                    structure["properties"][prop_name]["options"] = [
                        option.get('name', '') for option in options
                    ]
                elif prop_type == 'relation':
                    relation_id = prop_info.get('relation', {}).get('database_id', '')
                    structure["properties"][prop_name]["relation_db_id"] = relation_id
            
            logging.info(f"âœ… {db_name} DB êµ¬ì¡° í™•ì¸ ì™„ë£Œ ({len(properties)}ê°œ ì†ì„±)")
            return structure
            
        except Exception as e:
            logging.error(f"âŒ {db_name} DB êµ¬ì¡° í™•ì¸ ì‹¤íŒ¨: {str(e)}")
            return {
                "db_name": db_name,
                "db_id": db_id,
                "error": str(e)
            }
    
    def get_sample_data(self, db_name: str, db_id: str, limit: int = 3) -> List[Dict]:
        """ìƒ˜í”Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            logging.info(f"ğŸ“‹ {db_name} DB ìƒ˜í”Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì¤‘...")
            
            # í˜ì´ì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            response = self.notion.databases.query(
                database_id=db_id,
                page_size=limit
            )
            
            sample_data = []
            for page in response.get('results', []):
                page_data = {
                    "page_id": page.get('id', ''),
                    "properties": {}
                }
                
                # ê° ì†ì„±ì˜ ê°’ ì¶”ì¶œ
                for prop_name, prop_data in page.get('properties', {}).items():
                    prop_type = prop_data.get('type', 'unknown')
                    
                    if prop_type == 'title':
                        title_list = prop_data.get('title', [])
                        page_data["properties"][prop_name] = title_list[0].get('plain_text', '') if title_list else ''
                    elif prop_type == 'rich_text':
                        text_list = prop_data.get('rich_text', [])
                        page_data["properties"][prop_name] = text_list[0].get('plain_text', '') if text_list else ''
                    elif prop_type == 'select':
                        select_data = prop_data.get('select', {})
                        page_data["properties"][prop_name] = select_data.get('name', '') if select_data else ''
                    elif prop_type == 'multi_select':
                        multi_select_data = prop_data.get('multi_select', [])
                        page_data["properties"][prop_name] = [item.get('name', '') for item in multi_select_data]
                    elif prop_type == 'date':
                        date_data = prop_data.get('date', {})
                        page_data["properties"][prop_name] = date_data.get('start', '') if date_data else ''
                    elif prop_type == 'checkbox':
                        page_data["properties"][prop_name] = prop_data.get('checkbox', False)
                    elif prop_type == 'relation':
                        relation_data = prop_data.get('relation', [])
                        page_data["properties"][prop_name] = [item.get('id', '') for item in relation_data]
                    elif prop_type == 'rollup':
                        rollup_data = prop_data.get('rollup', {})
                        page_data["properties"][prop_name] = rollup_data.get('type', 'unknown')
                    else:
                        page_data["properties"][prop_name] = f"[{prop_type}]"
                
                sample_data.append(page_data)
            
            logging.info(f"âœ… {db_name} DB ìƒ˜í”Œ ë°ì´í„° {len(sample_data)}ê±´ í™•ì¸ ì™„ë£Œ")
            return sample_data
            
        except Exception as e:
            logging.error(f"âŒ {db_name} DB ìƒ˜í”Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")
            return []
    
    def run_comprehensive_check(self) -> Dict:
        """ëª¨ë“  DB ì¢…í•© ê²€ì‚¬"""
        logging.info("ğŸ” ì¡°ëŒ€í‘œë‹˜ ê¸°ì¡´ DB ì¢…í•© ê²€ì‚¬ ì‹œì‘")
        
        results = {
            "timestamp": logging.Formatter().formatTime(logging.LogRecord(
                name='', level=0, pathname='', lineno=0, msg='', args=(), exc_info=None
            )),
            "databases": {},
            "summary": {
                "total_databases": len(self.dbs),
                "successful_checks": 0,
                "failed_checks": 0
            }
        }
        
        for db_name, db_id in self.dbs.items():
            logging.info(f"\n--- {db_name} DB ê²€ì‚¬ ---")
            
            # êµ¬ì¡° í™•ì¸
            structure = self.check_database_structure(db_name, db_id)
            
            # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
            sample_data = self.get_sample_data(db_name, db_id)
            
            results["databases"][db_name] = {
                "structure": structure,
                "sample_data": sample_data
            }
            
            if "error" in structure:
                results["summary"]["failed_checks"] += 1
            else:
                results["summary"]["successful_checks"] += 1
        
        # ê²°ê³¼ ì €ì¥
        with open('existing_db_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        logging.info(f"\nğŸ¯ ê¸°ì¡´ DB ê²€ì‚¬ ì™„ë£Œ:")
        logging.info(f"   - ì„±ê³µ: {results['summary']['successful_checks']}ê°œ")
        logging.info(f"   - ì‹¤íŒ¨: {results['summary']['failed_checks']}ê°œ")
        logging.info(f"   - ê²°ê³¼ ì €ì¥: existing_db_analysis.json")
        
        return results
    
    def analyze_relationship_opportunities(self, results: Dict) -> Dict:
        """ê´€ê³„í˜• ì—°ê²° ê°€ëŠ¥ì„± ë¶„ì„"""
        logging.info("ğŸ”— ê´€ê³„í˜• ì—°ê²° ê°€ëŠ¥ì„± ë¶„ì„ ì¤‘...")
        
        # GIA ì‹œìŠ¤í…œ DB ì •ë³´
        gia_dbs = {
            "ë‰´ìŠ¤ì •ë³´": APIConfig.NOTION_NEWS_DATABASE_ID,
            "ì…ì°°ë‚™ì°°ê³µê³ ": APIConfig.NOTION_BID_DATABASE_ID
        }
        
        analysis = {
            "relationship_opportunities": [],
            "rollup_opportunities": [],
            "field_mapping_suggestions": {}
        }
        
        # ê° ê¸°ì¡´ DBë³„ë¡œ GIA ì‹œìŠ¤í…œê³¼ì˜ ì—°ê²° ê°€ëŠ¥ì„± ë¶„ì„
        for db_name, db_data in results["databases"].items():
            if "error" in db_data["structure"]:
                continue
                
            properties = db_data["structure"]["properties"]
            
            # ê´€ê³„í˜• ì†ì„± ì¶”ê°€ ê°€ëŠ¥ì„±
            analysis["relationship_opportunities"].append({
                "target_db": db_name,
                "suggested_relations": [
                    {
                        "name": "ê´€ë ¨ ë‰´ìŠ¤",
                        "target_db": "ë‰´ìŠ¤ì •ë³´DB",
                        "purpose": "í”„ë¡œì íŠ¸/íƒœìŠ¤í¬ì™€ ê´€ë ¨ëœ ë‰´ìŠ¤ ì •ë³´ ì—°ê²°"
                    },
                    {
                        "name": "ê´€ë ¨ ì…ì°°ì •ë³´",
                        "target_db": "ì…ì°°ë‚™ì°°ê³µê³ DB",
                        "purpose": "í”„ë¡œì íŠ¸/íƒœìŠ¤í¬ì™€ ê´€ë ¨ëœ ì…ì°°/ë‚™ì°° ì •ë³´ ì—°ê²°"
                    }
                ]
            })
            
            # ë¡¤ì—… ê¸°íšŒ ë¶„ì„
            analysis["rollup_opportunities"].append({
                "target_db": db_name,
                "suggested_rollups": [
                    {
                        "name": "ì¤‘ìš” ë‰´ìŠ¤ ìˆ˜",
                        "source": "ê´€ë ¨ ë‰´ìŠ¤",
                        "rollup_type": "count",
                        "filter": "ì¤‘ìš”ë„ê°€ 'ì¤‘ìš”' ë˜ëŠ” 'ë§¤ìš°ì¤‘ìš”'"
                    },
                    {
                        "name": "ìµœê·¼ ì…ì°°ê³µê³  ìˆ˜",
                        "source": "ê´€ë ¨ ì…ì°°ì •ë³´",
                        "rollup_type": "count", 
                        "filter": "ë‚ ì§œê°€ ìµœê·¼ 30ì¼ ì´ë‚´"
                    }
                ]
            })
        
        logging.info("âœ… ê´€ê³„í˜• ì—°ê²° ê°€ëŠ¥ì„± ë¶„ì„ ì™„ë£Œ")
        return analysis

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    checker = ExistingDBChecker()
    
    # ì¢…í•© ê²€ì‚¬ ì‹¤í–‰
    results = checker.run_comprehensive_check()
    
    # ê´€ê³„í˜• ì—°ê²° ë¶„ì„
    analysis = checker.analyze_relationship_opportunities(results)
    
    # ìµœì¢… ë³´ê³ ì„œ ìƒì„±
    final_report = {
        "db_analysis": results,
        "relationship_analysis": analysis,
        "recommendations": [
            "ê¸°ì¡´ í”„ë¡œì íŠ¸ DBì— 'ê´€ë ¨ ë‰´ìŠ¤' ê´€ê³„í˜• ì†ì„± ì¶”ê°€",
            "ê¸°ì¡´ íƒœìŠ¤í¬ DBì— 'ê´€ë ¨ ì…ì°°ì •ë³´' ê´€ê³„í˜• ì†ì„± ì¶”ê°€", 
            "ë¡¤ì—… ê¸°ëŠ¥ì„ í™œìš©í•œ ì¤‘ìš” ì •ë³´ ì§‘ê³„ í‘œì‹œ",
            "ì¡°ëŒ€í‘œë‹˜ ì›Œí¬í”Œë¡œìš°ì— ìµœì†Œí•œì˜ ë³€í™”ë¡œ ìµœëŒ€ íš¨ê³¼ ë‹¬ì„±"
        ]
    }
    
    with open('existing_db_final_report.json', 'w', encoding='utf-8') as f:
        json.dump(final_report, f, ensure_ascii=False, indent=2)
    
    print("\nğŸ‰ ê¸°ì¡´ DB ë¶„ì„ ì™„ë£Œ!")
    print("ğŸ“„ ê²°ê³¼ íŒŒì¼:")
    print("   - existing_db_analysis.json")
    print("   - existing_db_final_report.json")

if __name__ == "__main__":
    main() 